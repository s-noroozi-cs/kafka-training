--- scenario for ack and min insync replica 

	1. docker-compose up -d
	2. docker logs kafka_? | grep  "KafkaServer id="
	3. docker exec -it kafka_1 /bin/bash
	4. cd /opt/kafka/bin/
	5. ./kafka-topics.sh --bootstrap-server localhost:9092 --describe
	6. ./kafka-topics.sh --create --topic t1 \
						 --bootstrap-server localhost:9092
	7. ./kafka-topics.sh --create --topic t2 \
						 --bootstrap-server localhost:9092 \
						 --partitions 10
	8. ./kafka-topics.sh --create --topic t3 \
						 --bootstrap-server localhost:9092 \
						 --partitions 10 \
						 --replication-factor 3
	9. docker stop kafka_*
	10. ./kafka-topics.sh --bootstrap-server localhost:9092 --describe
	11. leader of some partition --> none
		to solve this issue: 
			./kafka-leader-election.sh --bootstrap-server localhost:9092 \
							--topic t2 \
							--partition 1 \
							--election-type unclean

			./kafka-leader-election.sh --bootstrap-server localhost:9092 \
							--election-type unclean \
							--path-to-json-file config.json

			{
				"partitions":[
					{"topic": "t2", "partition": 1},   
                    {"topic": "t2", "partition": 2}
                ]
            }

	--- create json file to define topic that required reasignment partitions
	{
		"topics": [
			{
				"topic":"t2"
			}
		]
		,"version":1
	}
	./kafka-reassign-partitions.sh --bootstrap-server localhost:9092 \
							   --generate \
							   --topics-to-move-json-file test-topic.json \
							   --broker-list "1001,1002,1003"

	Current partition replica assignment
		...
	Proposed partition reassignment configuration
		...

	copy content of Proposed to new file --> topic-part.cfg


		./kafka-reassign-partitions.sh --bootstrap-server localhost:9092 \
							--reassignment-json-file topic-part.cfg \
							--execute


	--- retention ---

	1. docker run -d --name zookeeper -p 2181:2181 zookeeper:3.7.0
	2. docker run -d --name kafka_1 --link zookeeper -p 9092:9092 \
			-e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 \
			-e KAFKA_LISTENERS=plaintext://:9092 \
			-e KAFKA_ADVERTISED_LISTENERS=plaintext://kafka_1:9092 \
			wurstmeister/kafka:2.13-2.8.1
	3. docker exec -it kafka_1 /bin/bash
	4. du -h /kafka
	5. ./kafka-topics.sh --create --topic t1 \
						 --bootstrap-server localhost:9092
	6. du -h /kafka
		./kafka-producer-perf-test.sh --topic t1 \
					--num-records 300000 --record-size 1000 \
	      			--throughput 1000 \
	      			--producer-props bootstrap.servers=localhost:9092
	7. du -h /kafka

	stop kafka and start with new config
	8. docker run -d --name zookeeper -p 2181:2181 zookeeper:3.7.0
	9. docker run -it --name kafka_1 --link zookeeper -p 9092:9092 \
			-e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 \
			-e KAFKA_LISTENERS=plaintext://:9092 \
			-e KAFKA_ADVERTISED_LISTENERS=plaintext://kafka_1:9092 \
			-e KAFKA_LOG_RETENTION_MS=3000 \
			-e KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS=5000 \
			-e KAFKA_LOG_SEGMENT_BYTES=20000 \
			wurstmeister/kafka:2.13-2.8.1
	10. du -h /kafka
	11. ./kafka-topics.sh --create --topic t1 \
						 --bootstrap-server localhost:9092
	12. ./kafka-producer-perf-test.sh --topic t1 \
					--num-records 300000 --record-size 1000 \
	      			--throughput 100 \
	      			--producer-props bootstrap.servers=localhost:9092
	13. watch "du -h /kafka"
	14. docker logs -f kafka_1


	--- compaction ---
		docker run -d --name zookeeper -p 2181:2181 zookeeper:3.7.0

		docker run -it --name kafka_1 --link zookeeper -p 9092:9092 \
			-e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 \
			-e KAFKA_LISTENERS=plaintext://:9092 \
			-e KAFKA_ADVERTISED_LISTENERS=plaintext://kafka_1:9092 \
			wurstmeister/kafka:2.13-2.8.1

		./kafka-topics.sh --create --topic t1 \
						 --bootstrap-server localhost:9092


	
	./kafka-console-consumer.sh \
		--bootstrap-server localhost:9092 \
		--topic t1 \
		--property print.key=true \
		--from-beginning


	./kafka-console-producer.sh \
		--bootstrap-server localhost:9092 \
		--topic t1 \
		--property parse.key=true \
		--property key.separator=:

	docker run -it --name kafka_1 --link zookeeper -p 9092:9092 \
			-e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 \
			-e KAFKA_LISTENERS=plaintext://:9092 \
			-e KAFKA_ADVERTISED_LISTENERS=plaintext://kafka_1:9092 \
			-e KAFKA_LOG_CLEANUP_POLICY=compact \
			-e KAFKA_LOG_CLEANER_MAX_COMPACTION_LAG_MS=100 \
			-e KAFAK_DELETE_RETENTION_MS=100 \
			wurstmeister/kafka:2.13-2.8.1


	--- compression --- 

	docker run -d --name zookeeper -p 2181:2181 zookeeper:3.7.0

	docker run -it --name kafka_1 --link zookeeper -p 9092:9092 \
			-e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 \
			-e KAFKA_LISTENERS=plaintext://:9092 \
			-e KAFKA_ADVERTISED_LISTENERS=plaintext://kafka_1:9092 \
			wurstmeister/kafka:2.13-2.8.1

	./kafka-topics.sh --create --topic t1 \
						 --bootstrap-server localhost:9092

	./kafka-producer-perf-test.sh --topic t1 \
					--num-records 300000 --record-size 10000 \
	      			--throughput 1000 \
	      			--producer-props bootstrap.servers=localhost:9092
		
	compression.type. 
		default: none
		support: gzip, snappy, lz4, zstd

	./kafka-topics.sh --create --topic t2 \
		--bootstrap-server localhost:9092 \
		--config compression.type=zstd \
		--replication-factor 1 \
		--partitions 1

	./kafka-producer-perf-test.sh --topic t2 \
					--num-records 300000 --record-size 10000 \
	      			--throughput 1000 \
	      			--producer-props bootstrap.servers=localhost:9092

	 metrics: 
	 	cpu usage  --> docker stats 
	 	disk usage --> du -h /kafka


	--- tls ---

	docker run -d --name zookeeper -p 2181:2181 zookeeper:3.7.0

	docker run -d --name kafka_1 --link zookeeper -p 9092:9092 \
			-e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 \
			-e KAFKA_LISTENERS=plaintext://:9092 \
			-e KAFKA_ADVERTISED_LISTENERS=plaintext://kafka_1:9092 \
			wurstmeister/kafka:2.13-2.8.1

	./kafka-topics.sh --create --topic t1 \
						 --bootstrap-server localhost:9092

	./kafka-console-producer.sh \
		--bootstrap-server localhost:9092 \
		--topic t1

	sudo tcpdump -i any port 9092 -n -X


	create key store and trus store using key store explore

	docker run -d --hostname kafka --name kafka --link zookeeper -p 9092:9092 \
			-v /Users/saeid/github/kafka-training/operation-scenarios:/certs \
			-e KAFKA_SECURITY_INTER_BROKER_PROTOCOL=SSL \
			-e KAFKA_SSL_ENABLED_PROTOCOLS=TLSv1.2 \
			-e KAFKA_SSL_CLIENT_AUTH=required \
			-e KAFKA_SSL_KEYSTORE_LOCATION=/certs/ks.jks \
			-e KAFKA_SSL_KEYSTORE_PASSWORD=123456 \
			-e KAFKA_SSL_KEY_PASSWORD=123456 \
			-e KAFKA_SSL_TRUSTSTORE_LOCATION=/certs/ts.jks \
			-e KAFKA_SSL_TRUSTSTORE_PASSWORD=123456 \
			-e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 \
			-e KAFKA_LISTENERS=SSL://:9092 \
			-e KAFKA_ADVERTISED_LISTENERS=SSL://kafka:9092 \
			wurstmeister/kafka:2.13-2.8.1

	connecting using offset explorer

	monitoring using tcpdump

	    	
